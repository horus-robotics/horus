---
title: Scheduler API Reference
description: Complete API reference for the Scheduler
order: 22
---

# Scheduler API Reference

The `Scheduler` orchestrates node execution, managing priorities, lifecycle, and the main tick loop.

## Creating a Scheduler

### `Scheduler::new()`

Create a new scheduler.

```rust
pub fn new() -> Self
```

**Returns**: A new `Scheduler` instance

**Example**:
```rust
use horus::prelude::*;

let mut scheduler = Scheduler::new();
```

## Adding Nodes

### `add(node, priority, logging)`

Add a node to the scheduler.

```rust
pub fn add(
    &mut self,
    node: Box<dyn Node>,
    priority: u32,
    logging_enabled: Option<bool>
) -> &mut Self
```

**Parameters**:
- `node`: Boxed node implementing the `Node` trait
- `priority`: Execution priority (0 = highest, 4 = lowest)
- `logging_enabled`: Optional logging flag (`Some(true)`, `Some(false)`, or `None` for default false)

**Returns**: Mutable reference to `Self` for method chaining

**Example**:
```rust
use horus::prelude::*;

let mut scheduler = Scheduler::new();

// Add with logging enabled
scheduler.add(Box::new(SensorNode::new()?), 0, Some(true));

// Add with logging disabled
scheduler.add(Box::new(ProcessorNode::new()?), 1, Some(false));

// Add with default logging (false)
scheduler.add(Box::new(ActuatorNode::new()?), 2, None);
```

**Priority Levels**:
- `0` - Critical (highest priority)
- `1` - High
- `2` - Normal (recommended for most nodes)
- `3` - Low
- `4` - Background (lowest priority)

**Method Chaining**:
```rust
scheduler
    .add(Box::new(sensor), 0, Some(true))
    .add(Box::new(controller), 1, Some(true))
    .add(Box::new(actuator), 2, Some(true));
```

### `name(name)`

Set the scheduler name (chainable).

```rust
pub fn name(self, name: &str) -> Self
```

**Parameters**:
- `name`: Name for this scheduler instance

**Returns**: `Self` for method chaining

**Example**:
```rust
let mut scheduler = Scheduler::new()
    .name("RobotController");
```

## Running the Scheduler

### `run()`

Run all added nodes continuously until stopped (Ctrl+C).

```rust
pub fn run(&mut self) -> Result<()>
```

**Returns**: `Result<()>` (always `Ok(())` when stopped gracefully)

**Example**:
```rust
scheduler.run()?;
```

**Behavior**:
- Initializes all nodes (calls `init()` once)
- Runs tick loop at ~60 FPS
- Executes nodes in priority order each tick
- Handles Ctrl+C gracefully
- Calls `shutdown()` on all nodes before exiting

### `run_for(duration)`

Run all nodes for a specified duration, then shutdown gracefully.

```rust
pub fn run_for(&mut self, duration: Duration) -> Result<()>
```

**Parameters**:
- `duration`: How long to run the scheduler

**Returns**: `Result<()>`

**Example**:
```rust
use std::time::Duration;

// Run for 10 seconds
scheduler.run_for(Duration::from_secs(10))?;

// Run for 500 milliseconds
scheduler.run_for(Duration::from_millis(500))?;
```

**Use Cases**:
- Integration testing with deterministic duration
- Benchmarking (measure performance over exact time period)
- Batch processing (run for N seconds, save results, repeat)
- CI/CD pipelines (automated testing with timeouts)

### `tick(node_names)`

Run only specific nodes continuously.

```rust
pub fn tick(&mut self, node_names: &[&str]) -> Result<()>
```

**Parameters**:
- `node_names`: Array of node names to run

**Returns**: `Result<()>`

**Example**:
```rust
// Run only sensor and processor nodes
scheduler.tick(&["SensorNode", "ProcessorNode"])?;
```

### `tick_for(node_names, duration)`

Run specific nodes for a specified duration.

```rust
pub fn tick_for(&mut self, node_names: &[&str], duration: Duration) -> Result<()>
```

**Parameters**:
- `node_names`: Array of node names to run
- `duration`: How long to run the selected nodes

**Returns**: `Result<()>`

**Example**:
```rust
use std::time::Duration;

// Test specific nodes for 5 seconds
scheduler.tick_for(
    &["SensorNode", "ControllerNode"],
    Duration::from_secs(5)
)?;
```

**Use Cases**:
- Isolated node testing
- Performance profiling of specific subsystems
- Debugging specific node interactions

## Control Methods

### `stop()`

Stop the scheduler (from another thread).

```rust
pub fn stop(&self)
```

**Example**:
```rust
use std::sync::Arc;

let scheduler = Arc::new(Mutex::new(Scheduler::new()));

// Clone for another thread
let scheduler_clone = scheduler.clone();

// Stop from another thread
std::thread::spawn(move || {
    std::thread::sleep(Duration::from_secs(10));
    scheduler_clone.lock().unwrap().stop();
});
```

### `is_running()`

Check if the scheduler is currently running.

```rust
pub fn is_running(&self) -> bool
```

**Returns**: `true` if scheduler is running, `false` otherwise

**Example**:
```rust
while scheduler.is_running() {
    // Do something
}
```

## Monitoring Methods

### `get_node_list()`

Get list of all added node names.

```rust
pub fn get_node_list(&self) -> Vec<String>
```

**Returns**: Vector of node names

**Example**:
```rust
let nodes = scheduler.get_node_list();
for node_name in nodes {
    println!("Added node: {}", node_name);
}
```

### `get_node_info(name)`

Get detailed information about a specific node.

```rust
pub fn get_node_info(&self, name: &str) -> Option<HashMap<String, String>>
```

**Parameters**:
- `name`: Name of the node

**Returns**: `Some(HashMap)` with node info, or `None` if not found

**Keys**:
- `"name"` - Node name
- `"priority"` - Execution priority
- `"logging_enabled"` - Logging state ("true" or "false")

**Example**:
```rust
if let Some(info) = scheduler.get_node_info("SensorNode") {
    println!("Priority: {}", info.get("priority").unwrap());
    println!("Logging: {}", info.get("logging_enabled").unwrap());
}
```

### `get_monitoring_summary()`

Get summary of all nodes (name and priority).

```rust
pub fn get_monitoring_summary(&self) -> Vec<(String, u32)>
```

**Returns**: Vector of `(node_name, priority)` tuples

**Example**:
```rust
let summary = scheduler.get_monitoring_summary();
for (name, priority) in summary {
    println!("{}: priority {}", name, priority);
}
```

### `set_node_logging(name, enabled)`

Enable or disable logging for a specific node.

```rust
pub fn set_node_logging(&mut self, name: &str, enabled: bool) -> bool
```

**Parameters**:
- `name`: Node name
- `enabled`: `true` to enable logging, `false` to disable

**Returns**: `true` if node was found, `false` otherwise

**Example**:
```rust
// Disable logging for SensorNode
scheduler.set_node_logging("SensorNode", false);

// Enable logging for ProcessorNode
scheduler.set_node_logging("ProcessorNode", true);
```

## Complete Examples

### Example 1: Production Application (Run Forever)

```rust
use horus::prelude::*;

fn main() -> Result<()> {
    let mut scheduler = Scheduler::new()
        .name("RobotController");

    scheduler
        .add(Box::new(SensorNode::new()?), 0, Some(true))
        .add(Box::new(ProcessorNode::new()?), 1, Some(true));

    // Run until Ctrl+C
    scheduler.run()?;

    Ok(())
}
```

### Example 2: Integration Test (Run for Duration)

```rust
use horus::prelude::*;
use std::time::Duration;

#[test]
fn test_sensor_processing() -> Result<()> {
    let mut scheduler = Scheduler::new();

    scheduler
        .add(Box::new(SensorNode::new()?), 0, Some(true))
        .add(Box::new(ProcessorNode::new()?), 1, Some(true));

    // Run for 5 seconds, then check results
    scheduler.run_for(Duration::from_secs(5))?;

    // Verify results after graceful shutdown
    assert!(verify_processing_complete());
    Ok(())
}
```

### Example 3: Benchmark Performance

```rust
use horus::prelude::*;
use std::time::{Duration, Instant};

fn main() -> Result<()> {
    let mut scheduler = Scheduler::new();
    scheduler.add(Box::new(HighSpeedNode::new()?), 0, Some(false));

    let start = Instant::now();

    // Run for exactly 60 seconds
    scheduler.run_for(Duration::from_secs(60))?;

    let elapsed = start.elapsed();
    let message_count = get_message_count();

    println!("Processed {} messages in {:?}", message_count, elapsed);
    println!("Rate: {} msg/sec", message_count as f64 / elapsed.as_secs_f64());

    Ok(())
}
```

### Example 4: Debug Specific Nodes

```rust
use horus::prelude::*;
use std::time::Duration;

fn main() -> Result<()> {
    let mut scheduler = Scheduler::new();

    scheduler
        .add(Box::new(SensorNode::new()?), 0, Some(true))
        .add(Box::new(ControllerNode::new()?), 1, Some(true))
        .add(Box::new(ActuatorNode::new()?), 2, Some(true));

    // Test only sensor and controller for 10 seconds
    scheduler.tick_for(
        &["SensorNode", "ControllerNode"],
        Duration::from_secs(10)
    )?;

    Ok(())
}
```

### Example 5: Batch Processing Loop

```rust
use horus::prelude::*;
use std::time::Duration;

fn main() -> Result<()> {
    let mut scheduler = Scheduler::new();
    scheduler.add(Box::new(DataProcessor::new()?), 0, Some(true));

    // Process in 1-hour batches
    for batch in 0..24 {
        println!("Starting batch {}...", batch);

        // Run for 1 hour
        scheduler.run_for(Duration::from_secs(3600))?;

        // Save checkpoint between batches
        save_checkpoint(batch)?;

        println!("Batch {} complete", batch);
    }

    Ok(())
}
```

## Execution Order

Nodes execute in **priority order** each tick:

```
Tick 1:
   Node with priority 0 (Critical)
   Node with priority 1 (High)
   Node with priority 2 (Normal)
   Node with priority 3 (Low)
   Node with priority 4 (Background)

Sleep 16ms (~60 FPS)

Tick 2:
   Repeat...
```

**Within the same priority**: Nodes execute in the order they were added.

## Signal Handling

The scheduler automatically handles **Ctrl+C** (SIGINT):

1. User presses Ctrl+C
2. Scheduler stops accepting new ticks
3. Current tick completes
4. `shutdown()` called on all nodes
5. Cleanup and exit

**Force termination**: Press Ctrl+C a second time for immediate exit.

## Performance

### Tick Rate

Default: **~60 FPS** (16ms sleep between ticks)

Actual rate depends on:
- Number of nodes
- Node tick duration
- System load

**Monitor actual rate** using node metrics:
```rust
let metrics = ctx.metrics();
let actual_hz = 1000.0 / metrics.avg_tick_duration_ms;
```

### Best Practices

**Keep ticks fast**: Each tick should complete in < 16ms (ideally < 1ms)

**Use priorities wisely**:
- Critical (0): Safety, emergency stop
- High (1): Control loops
- Normal (2): Most nodes
- Low (3): Logging, monitoring
- Background (4): Slow periodic tasks

**Profile slow nodes**:
```rust
fn tick(&mut self, ctx: Option<&mut NodeInfo>) {
    let start = Instant::now();

    // Do work...

    if let Some(ctx) = ctx {
        let duration = start.elapsed();
        if duration.as_millis() > 10 {
            ctx.log_warning(&format!("Slow tick: {}ms", duration.as_millis()));
        }
    }
}
```

## Registry and Monitoring

The scheduler writes metadata to `~/.horus_registry.json` for monitoring tools:

```json
{
  "pid": 12345,
  "scheduler_name": "RobotController",
  "working_dir": "/path/to/project",
  "nodes": [
    {
      "name": "SensorNode",
      "priority": 0,
      "state": "Running",
      "health": "Healthy",
      "publishers": [{"topic": "sensor_data", "type": "f32"}],
      "subscribers": []
    }
  ]
}
```

This file is:
- Created when `run()` starts
- Updated every 5 seconds with node states
- Deleted when scheduler stops
- Used by `horus dashboard` to monitor the system

## Heartbeats

The scheduler writes node heartbeats to `/dev/shm/horus/heartbeats/`:

```bash
$ cat /dev/shm/horus/heartbeats/SensorNode
{
  "state": "Running",
  "health": "Healthy",
  "tick_count": 3600,
  "target_rate_hz": 60,
  "actual_rate_hz": 59,
  "error_count": 0
}
```

Heartbeats are:
- Written after each tick
- Used for real-time monitoring
- Cleaned up on shutdown

## Common Patterns

### Simple Application

```rust
let mut scheduler = Scheduler::new();
scheduler.add(Box::new(my_node), 2, Some(true));
scheduler.run()?;
```

### Multi-Priority System

```rust
let mut scheduler = Scheduler::new();

// Critical safety monitor
scheduler.add(Box::new(safety), 0, Some(true));

// Control loop
scheduler.add(Box::new(controller), 1, Some(true));

// Sensors
scheduler.add(Box::new(lidar), 2, Some(true));
scheduler.add(Box::new(camera), 2, Some(true));

// Logging
scheduler.add(Box::new(logger), 4, Some(false));

scheduler.run()?;
```

### Selective Execution

```rust
// Run only specific nodes for testing
scheduler.tick(&["SensorNode", "ProcessorNode"])?;
```

## Troubleshooting

### Nodes not executing

Check added nodes:
```rust
let nodes = scheduler.get_node_list();
println!("Added nodes: {:?}", nodes);
```

### High CPU usage

Profile tick durations:
```rust
if let Some(info) = scheduler.get_node_info("SlowNode") {
    println!("Node info: {:?}", info);
}
```

### Logs too verbose

Disable logging for specific nodes:
```rust
scheduler.set_node_logging("VerboseNode", false);
```

## See Also

- [Node API Reference](/api-node) - Node implementation
- [Hub API Reference](/api-hub) - Pub/sub communication
- [Core Concepts: Scheduler](/core-concepts-scheduler) - Detailed guide
