---
title: Simulation
description: Test your robots in virtual environments with sim2d and sim3d
order: 25
---

# Simulation

Test and validate your robot algorithms in virtual environments before deploying to real hardware. HORUS provides two simulation tools optimized for different use cases.

---

## Overview

| Simulator | Status | Dimensions | Use Case | Performance |
|-----------|--------|------------|----------|-------------|
| **sim2d** |  **Active Development** | 2D Top-Down | Fast prototyping, navigation | 1000+ Hz headless |
| **sim3d** |  **Available** | Full 3D | Realistic testing, RL training | 60 FPS visual, 100K+ steps/sec RL |

**Key Benefits:**
-  **Same code works in sim and reality** - Write once, deploy anywhere
-  **HORUS-native** - Direct Hub integration, no middleware
-  **Sub-microsecond IPC** - Realistic latency testing
-  **CI/CD ready** - Headless mode for automated testing

---

## sim2d - 2D Robotics Simulator

>  **Status:** Active Development - Core features working, polish ongoing

### What is sim2d?

A lightweight **2D top-down simulator** built with Bevy and Rapier2D for fast iteration and testing.

**Perfect for:**
-  Navigation algorithm development
-  Multi-robot coordination
-  Path planning testing
-  Sensor simulation (LiDAR, odometry, IMU)
-  CI/CD automated testing

**Not designed for:**
-  Realistic 3D visualization
-  Camera/vision simulation
-  Complex robot modeling

### Quick Start

#### Installation

```bash
# Ubuntu/Debian - Install dependencies
sudo apt install -y pkg-config libx11-dev libasound2-dev libudev-dev

# Set environment variables
export PKG_CONFIG_ALLOW_SYSTEM_LIBS=1
export PKG_CONFIG_ALLOW_SYSTEM_CFLAGS=1
```

#### Run sim2d

```bash
# Launch simulator
horus sim2d

# Or with specific options
horus sim2d --world warehouse.yaml
horus sim2d --headless  # No GUI (for testing)
```

### Features

#### Visual Mode
- Real-time 2D rendering with Bevy
- Top-down view of robots and environment
- Debug visualization (lidar rays, paths, collision shapes)
- Interactive camera controls

#### Physics
- Rapier2D physics engine
- Realistic differential drive kinematics
- Collision detection and response
- Configurable physics rate (default: 240 Hz)

#### Sensors
- **2D LiDAR**: 360Â° scanning with configurable resolution
- **Odometry**: Wheel encoder simulation with realistic noise
- **IMU**: Angular velocity and acceleration
- **Ground truth**: Perfect pose for debugging

#### HORUS Integration

Your robot code works **unchanged** in simulation:

```rust
use horus::prelude::*;
use horus_library::messages::CmdVel;

struct NavigationNode {
    cmd_pub: Hub<CmdVel>,
    scan_sub: Hub<LaserScan>,
}

impl NavigationNode {
    fn new() -> Result<Self> {
        Ok(Self {
            cmd_pub: Hub::new("cmd_vel")?,
            scan_sub: Hub::new("scan")?,
        })
    }
}

impl Node for NavigationNode {
    fn name(&self) -> &'static str {
        "NavigationNode"
    }

    fn tick(&mut self, mut ctx: Option<&mut NodeInfo>) {
        // Read simulated LiDAR
        if let Some(scan) = self.scan_sub.recv(&mut ctx) {
            // Compute motion command
            let cmd = avoid_obstacles(&scan);

            // Send to simulated robot
            self.cmd_pub.send(cmd, &mut ctx).ok();
        }
    }
}
```

**Same topics work in simulation and reality:**
- `/cmd_vel` - Velocity commands
- `/scan` - LiDAR data
- `/odom` - Odometry
- `/tf` - Transform frames

### Usage Examples

#### Test Navigation Algorithm

```bash
# Terminal 1: Launch simulator with maze
horus sim2d --world maze.yaml

# Terminal 2: Run your navigation code
horus run navigation.rs --release

# Terminal 3: Monitor performance
horus dashboard
```

#### Headless Testing (CI/CD)

```bash
#!/bin/bash
# Automated test script

# Start simulator in headless mode
horus sim2d --headless &
SIM_PID=$!

# Wait for simulator to initialize
sleep 2

# Run test
timeout 30 horus run test_navigation.rs --release
TEST_RESULT=$?

# Stop simulator
kill $SIM_PID

exit $TEST_RESULT
```

#### Custom Scenarios

Create a scenario configuration file:

```yaml
# warehouse.yaml
world:
  size: [20.0, 20.0]

obstacles:
  - type: box
    position: [5.0, 5.0]
    size: [2.0, 1.0]

  - type: circle
    position: [10.0, 8.0]
    radius: 1.5

robots:
  - name: robot1
    position: [1.0, 1.0]
    orientation: 0.0
```

Load it:
```bash
horus sim2d --world warehouse.yaml
```

### Configuration

sim2d can be configured via `sim2d_config.yaml`:

```yaml
physics:
  rate_hz: 240
  gravity: [0.0, 0.0]

rendering:
  window_size: [1280, 720]
  target_fps: 60

robot:
  max_linear_vel: 0.5  # m/s
  max_angular_vel: 2.0 # rad/s
  wheel_radius: 0.05   # meters
  wheel_separation: 0.2

sensors:
  lidar:
    num_rays: 360
    max_range: 10.0
    fov: 6.28318  # 2Ï€ (360Â°)
    rate_hz: 10
    noise_std: 0.01
```

### Command Reference

```bash
horus sim2d [OPTIONS]

Options:
  --headless                 Run without GUI (for CI/CD)
  --world <FILE>             World configuration file
  --world-image <FILE>       World image file (PNG, JPG, PGM)
  --resolution <FLOAT>       Resolution in meters per pixel
  --threshold <0-255>        Obstacle threshold (darker = obstacle)
  --robot <FILE>             Robot configuration file
  --topic <PREFIX>           HORUS topic prefix (default: /robot)
  --name <NAME>              Robot name for logging (default: robot)
  -h, --help                 Show help
```

### Performance

**Visual Mode:**
- Rendering: 60 FPS
- Physics: 240 Hz
- IPC latency: 85-167ns

**Headless Mode:**
- Physics: 1000+ Hz
- IPC latency: &lt;100ns
- Memory: ~50MB

### Known Limitations

As sim2d is under active development, be aware of:

-  Limited to 2D top-down view
-  No camera/vision sensors yet
-  Basic visualization (no shadows, advanced graphics)
-  Documentation being updated

For production use, we recommend:
- Testing critical algorithms in sim2d first
- Validating on real hardware before deployment

---

## sim3d - 3D Robotics Simulator with RL Support

>  **Status:** Available - Core features implemented, advanced features in development

### Overview

A **production-grade 3D simulator** built with Bevy and Rapier3D, designed as the evolution of sim2d with first-class reinforcement learning support.

### Features

#### Dual-Mode Operation

**Visual Mode (60 FPS):**
- Realistic 3D rendering with PBR materials
- Dynamic shadows and lighting
- Multiple camera views (orbital, follow, first-person)
- Debug visualization (TF frames, collision shapes, sensor FOVs)
- Interactive scene editor

**Headless Mode (100K+ steps/sec):**
- No rendering overhead
- Vectorized environments (1024+ parallel instances)
- Fast reset (&lt;1ms)
- Optimized for RL training

#### Robot Support

**URDF Loading:**
- Load standard robot descriptions
- Automatic TF tree generation
- Mesh loading (GLTF, STL, OBJ)
- Material and texture support
- Joint controller generation

**Example robots:**
- TurtleBot3 (differential drive)
- UR5e (6-DOF manipulator)
- Quadrotors (flight control)
- Custom robots via URDF

#### Advanced Physics

Built on **Rapier3D** with:
- Rigid body dynamics
- Articulated robots (multi-DOF joints)
- Collision detection with continuous collision detection (CCD)
- Constraint solvers (revolute, prismatic, fixed)
- Contact forces and friction
- 240 Hz physics rate

#### 3D Sensors

**LiDAR 3D:**
- 360Â° horizontal Ã— 30Â° vertical scanning
- Configurable resolution (e.g., 720Ã—16 rays)
- Realistic noise models
- Point cloud generation (&lt;5ms)

**RGB-D Camera:**
- RGB images
- Depth maps
- Configurable resolution and FOV
- Lens distortion simulation

**IMU:**
- Linear acceleration
- Angular velocity
- Realistic drift and noise

**GPS:**
- Global positioning with noise
- Configurable accuracy

**Force/Torque Sensors:**
- Contact force measurement
- Joint torque feedback

#### Transform Frames (TF)

**ROS-compatible TF system:**
- Hierarchical frame tree
- Automatic TF publishing to `/tf` topic
- Transform lookups between any frames
- Visualization of frame axes
- URDF-based frame hierarchy

```rust
// Get transform between frames
let transform = tf_tree.get_transform("base_link", "camera_link")?;

// Visualize TF tree
horus sim3d --tf-view
```

#### Reinforcement Learning

**Gymnasium Interface:**
```python
import gymnasium as gym
import horus_sim3d

# Create vectorized environment (1024 parallel instances)
env = gym.make_vec("HorusNav3D-v0", num_envs=1024)

obs, info = env.reset()

for step in range(1_000_000):
    actions = policy(obs)
    obs, rewards, dones, truncated, info = env.step(actions)

    # 100K+ steps per second!
```

**Domain Randomization:**
- Physics parameters (mass, friction, damping)
- Visual appearance (colors, textures, lighting)
- Sensor noise (gaussian, dropout, latency)
- Environment layout (randomized obstacles)

**Built-in Tasks:**
- Navigation (point-to-point)
- Obstacle avoidance
- Object manipulation (pick & place)
- Racing (time trial, multi-agent)

#### Scene Management

**Gazebo SDF Import:**
```bash
# Import Gazebo world
horus sim3d --import-sdf warehouse.world
```

**Runtime Spawning:**
```rust
// Spawn objects at runtime
scene.spawn_box(position, size, material);
scene.spawn_urdf("turtlebot3.urdf", pose);
```

**Save/Load Scenes:**
```bash
# Save current scene
horus sim3d --save-scene my_world.yaml

# Load scene
horus sim3d --scene my_world.yaml
```

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  User Interface                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CLI          â”‚ GUI (egui)   â”‚ Python (Gym)          â”‚
â”‚ horus sim3d  â”‚ Debug panels â”‚ RL training           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Simulation Core (Bevy ECS)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Physics   â”‚  â”‚  Sensors   â”‚  â”‚  TF System   â”‚ â”‚
â”‚  â”‚ (Rapier3D) â”‚  â”‚ Simulation â”‚  â”‚  (frames)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”‚               â”‚                â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         HORUS Hub Bridge                     â”‚  â”‚
â”‚  â”‚  â€¢ Publish sensor data                       â”‚  â”‚
â”‚  â”‚  â€¢ Subscribe to cmd_vel                      â”‚  â”‚
â”‚  â”‚  â€¢ Publish /tf transforms                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Visual Renderingâ”‚        â”‚  Headless RL Mode      â”‚
â”‚  (60 FPS)        â”‚        â”‚  (100K+ steps/sec)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technical Stack

**Core:**
- Bevy 0.15 (ECS + rendering)
- Rapier3D 0.22 (physics)
- nalgebra (math)

**Robot Loading:**
- urdf-rs (URDF parsing)
- GLTF/STL/OBJ support

**RL:**
- PyO3 (Python bindings)
- Gymnasium interface
- Rayon (parallel processing)

**Pure Rust:**
- Memory safe
- Cross-platform
- Single binary

### Planned Command Interface

```bash
# Visual mode (default)
horus sim3d

# Headless RL training
horus sim3d --headless --num-envs 1024

# Load URDF robot
horus sim3d --robot turtlebot3.urdf

# Import Gazebo world
horus sim3d --import-sdf warehouse.world

# Enable TF visualization
horus sim3d --tf-view

# Debug mode with editor
horus sim3d --editor

# Specific scenario
horus sim3d --scenario manipulation_task
```

### Python RL Example

```python
# train_navigation.py
import gymnasium as gym
from stable_baselines3 import PPO
import horus_sim3d

# Create environment
env = gym.make_vec("HorusNav3D-v0",
                   num_envs=1024,
                   domain_randomization=True)

# Train agent
model = PPO("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=10_000_000)

# Save policy
model.save("navigation_policy")

# Evaluate in visual mode
eval_env = gym.make("HorusNav3D-v0", render_mode="human")
obs, _ = eval_env.reset()

for _ in range(1000):
    action, _ = model.predict(obs)
    obs, reward, done, truncated, info = eval_env.step(action)
    if done or truncated:
        obs, _ = eval_env.reset()
```

### Development Roadmap

**Phase 1: Core Foundation** (Q1 2026)
-  Technical specification complete
- ğŸš§ Bevy + Rapier3D integration
- ğŸš§ Basic robot spawning
- ğŸš§ Camera controls

**Phase 2: Robot Support** (Q2 2026)
- ğŸš§ URDF loading
- ğŸš§ TF system implementation
- ğŸš§ Articulated robots
- ğŸš§ Joint controllers

**Phase 3: Sensors** (Q2 2026)
- ğŸš§ LiDAR 3D
- ğŸš§ RGB-D camera
- ğŸš§ IMU, GPS, encoders
- ğŸš§ Sensor noise models

**Phase 4: RL Features** (Q3 2026)
- ğŸš§ Headless mode optimization
- ğŸš§ Vectorized environments
- ğŸš§ Python Gymnasium bindings
- ğŸš§ Domain randomization
- ğŸš§ Built-in tasks

**Phase 5: Polish** (Q3-Q4 2026)
- ğŸš§ Scene editor
- ğŸš§ Gazebo SDF import
- ğŸš§ Documentation
- ğŸš§ Example projects

### Performance Targets

| Metric | Target |
|--------|--------|
| Visual FPS | 60 FPS |
| Physics rate | 240 Hz |
| Headless step rate | 100,000+ steps/sec (1024 envs) |
| LiDAR generation | &lt;5ms (720Ã—16 rays) |
| URDF loading | &lt;500ms (TurtleBot3) |
| Reset time | &lt;1ms (fast reset) |
| Memory (visual) | &lt;500MB (single robot) |
| Memory (headless) | &lt;50MB per environment |

---

## Sim-to-Real Transfer

### Why HORUS Simulators Work for Real Robots

**1. Identical Communication:**
```rust
// Same code in simulation and reality
let cmd_pub = Hub::<CmdVel>::new("cmd_vel")?;
let scan_sub = Hub::<LaserScan>::new("scan")?;

// HORUS handles whether it's sim or real hardware
```

**2. Realistic Latency:**
- Sim IPC: 85-167ns (sim2d), ~300ns (sim3d)
- Real robot serial: 1-10ms
- Sim is actually *faster* than real hardware

**3. Same Message Types:**
```rust
// horus_library/messages - works everywhere
use horus_library::messages::{CmdVel, LaserScan, Odometry};
```

**4. Physics Accuracy:**
- Rapier physics engine (production-grade)
- Realistic kinematics
- Accurate collision detection
- Configurable noise models

### Best Practices

**1. Start in Simulation:**
```bash
# Develop in sim2d (fast iteration)
horus sim
horus run navigation.rs

# Refine in sim3d (realistic testing)
horus sim3d --robot your_robot.urdf

# Deploy to real hardware
horus run --remote 192.168.1.100 navigation.rs
```

**2. Use Realistic Parameters:**
```yaml
# Match real robot specs
robot:
  max_linear_vel: 0.22   # Your robot's max speed
  max_angular_vel: 2.84
  wheel_radius: 0.033
  wheel_separation: 0.16
```

**3. Test with Noise:**
```yaml
sensors:
  lidar:
    noise_std: 0.01      # Realistic sensor noise
  odometry:
    drift_rate: 0.001    # Wheel slip
```

**4. Gradual Transfer:**
1. Perfect sim (no noise)  Algorithm works
2. Sim with noise  Algorithm robust
3. Real hardware  Fine-tune parameters

---

## Comparison with Other Simulators

| Feature | sim2d | sim3d (planned) | Gazebo | Webots | Isaac Sim |
|---------|-------|-----------------|--------|--------|-----------|
| **Dimensions** | 2D | 3D | 3D | 3D | 3D |
| **Physics** | Rapier2D | Rapier3D | ODE/Bullet | ODE | PhysX |
| **HORUS Native** |  Yes |  Yes |  No |  No |  No |
| **IPC Latency** | 85-167ns | ~300ns | 10ms+ | 10ms+ | N/A |
| **Headless Speed** | 1000+ Hz | 100K+ steps/sec | 100 Hz | 100 Hz | 1000+ Hz |
| **RL Ready** |  Basic |  Yes |  Plugins |  Plugins |  Yes |
| **URDF Support** |  No |  Yes |  Yes |  Yes |  Yes |
| **Language** | Rust | Rust | C++ | C++ | Python |
| **License** | MIT | MIT | Apache | Apache | Proprietary |

**When to use each:**
- **sim2d**: Fast 2D navigation prototyping, CI/CD testing
- **sim3d**: Realistic 3D testing, RL training, complex robots
- **Gazebo**: ROS integration, existing ROS packages
- **Webots**: Education, established workflows
- **Isaac Sim**: NVIDIA GPU, photorealistic rendering, large-scale RL

---

## Getting Help

### Documentation
- sim2d: `/home/lord-patpak/horus/HORUS/horus_library/tools/sim2d/README.md`
- sim3d spec: `/home/lord-patpak/horus/HORUS/horus_library/tools/sim3d/SIM3D_SPEC.md`

### Community
- GitHub Discussions: https://github.com/softmata/horus/discussions
- Discord: Ask in #simulation channel
- Issues: Report bugs at https://github.com/softmata/horus/issues

### Examples

Find simulation examples in:
```bash
horus_library/apps/
â”œâ”€â”€ snakesim/        # Snake game (sim2d demo)
â”œâ”€â”€ tanksim/         # Tank simulation (sim2d)
â””â”€â”€ sim3d_examples/  # sim3d examples (coming soon)
```

---

## Contributing

Help shape HORUS simulation tools:

**sim2d (Active Development):**
-  Report bugs and issues
-  Suggest features and improvements
-  Improve documentation
- ğŸ§ª Add test scenarios

**sim3d (Upcoming):**
- ğŸ’¬ Provide feedback on specification
-  Suggest priority features
- ğŸ¤ Volunteer for implementation

See [Contributing Guide](/contributing) for details.

---

## Roadmap

### sim2d
-  Basic 2D physics and rendering
-  LiDAR sensor simulation
-  HORUS Hub integration
- ğŸš§ Multi-robot support (in progress)
- ğŸš§ Additional sensors (camera, IMU)
-  Scene editor
-  Scenario library

### sim3d
-  Complete technical specification
-  Core implementation (Q1-Q2 2026)
-  URDF support (Q2 2026)
-  3D sensors (Q2 2026)
-  RL features (Q3 2026)
-  Beta release (Q4 2026)

---

## Next Steps

**Ready to simulate?**

1. **[Install HORUS](/getting-started/installation)** - Set up your environment
2. **[Quick Start](/getting-started/quick-start)** - Build your first robot
3. **[Try sim2d](https://github.com/softmata/horus/tree/main/horus_library/tools/sim2d)** - Start simulating
4. **[Join Discord](https://discord.gg/horus)** - Connect with the community

**Questions?**
- Read the [FAQ](/faq)
- Check [Troubleshooting](/troubleshooting)
- Ask on [GitHub Discussions](https://github.com/softmata/horus/discussions)
